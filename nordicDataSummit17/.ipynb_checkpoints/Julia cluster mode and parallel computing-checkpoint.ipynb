{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel computing in Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On CPU: Multi-process on multiple machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running on one core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function calc_pi(samples)\n",
    "    counter = 0\n",
    "    for i in 1:samples\n",
    "        x, y = rand(2)\n",
    "        if (x^2 + y^2 <=1)\n",
    "            counter += 1\n",
    "        end\n",
    "    end\n",
    "    π = 4 * counter / samples\n",
    "    return π\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 1e8\n",
    "@time calc_pi(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nprocs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding more processes is a one-liner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addprocs(3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of processes\n",
    "println(\"\"\"\n",
    "$(nprocs())\n",
    "$(workers())\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomVal_local = rand(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomVal_worker = remotecall(rand, 3, 2, 2) # <--- Remote call returns remote reference (Future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blabla = fetch(randomVal_worker) # <--- Cached locally "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nicer syntax with @spawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomVal1 = @spawn rand(2,2)\n",
    "#fetch(randomVal)\n",
    "\n",
    "randomVal2 = @spawn rand(2,2)\n",
    "randomVal3 = @spawn rand(2,2)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumVal = fetch(randomVal2) + fetch(randomVal2) + fetch(randomVal2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run @spawn on all available processes with @parallel. Pretty great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function parallel_calc_pi(samples)\n",
    "    counter = @parallel (+) for i=1:samples\n",
    "        x, y = rand(2)\n",
    "        ifelse(x^2 + y^2 <= 1, 1, 0)\n",
    "    end\n",
    "    π = 4 * counter / samples\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=1e8\n",
    "@time parallel_calc_pi(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear workers on all hosts\n",
    "rmprocs(workers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add some more on another host\n",
    "addprocs([(\"root@10.4.1.6:6666\",2), (\"root@10.4.1.4:6666\",2)], tunnel=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --> Multiple hosts are not necessarily a benefit\n",
    "* Access to memory\n",
    "* Communication\n",
    "* Sharing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anotherStupidMatrix = rand(100,100)\n",
    "calcMyStupidMatrix = @spawn inv(anotherStupidMatrix)\n",
    "\n",
    "lastPointlessMatrixIPromise = @spawn inv(rand(100,100))\n",
    "# fetch() and so on and so forth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What about threads and co-routines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On a single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDAnative, CUDAdrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function kernel_dist(X::AbstractVector{Float32}, Y::AbstractVector{Float32}, out::AbstractVector{Float32})\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    out[i] = (X[i]-0.5)^2 + (Y[i]-0.5)^2\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = Int64(5e8)\n",
    "a = rand(Float32, (samples))\n",
    "b = rand(Float32, (samples));\n",
    "a_cu = CuArray(a)\n",
    "b_cu = CuArray(b)\n",
    "c_cu = similar(a_cu);\n",
    "n = length(a)\n",
    "\n",
    "ctx = CuCurrentContext()\n",
    "dev = device(ctx)\n",
    "max_threads = attribute(dev, CUDAdrv.MAX_THREADS_PER_BLOCK)\n",
    "threads = min(max_threads, n)\n",
    "blocks = ceil(Int, n/threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time @cuda (blocks, threads) kernel_dist(a_cu, b_cu, c_cu)\n",
    "@time c = Array(c_cu)\n",
    "@time destroy!(ctx)\n",
    "@time pi_single = 4*count(x->x<0.25,c)/length(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On GPU's located on multiple machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmprocs(workers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "addprocs([(\"root@10.4.1.6:6666\",1), (\"root@10.4.1.4:6666\",1)], tunnel=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nprocs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using CUDAnative, CUDAdrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function kernel_dist(X::AbstractVector{Float32}, Y::AbstractVector{Float32}, gpu_cu::AbstractVector{Float32})\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    gpu_cu[i] = (X[i]-0.5)^2 + (Y[i]-0.5)^2\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function distmontegpu(samples)\n",
    "    a = rand(Float32, (samples))\n",
    "    b = rand(Float32, (samples));\n",
    "    a_cu = CuArray(a)\n",
    "    b_cu = CuArray(b)\n",
    "    c_cu = similar(a_cu);\n",
    "    n = length(a)\n",
    "    ctx = CuCurrentContext()\n",
    "    dev = device(ctx)\n",
    "    max_threads = attribute(dev, CUDAdrv.MAX_THREADS_PER_BLOCK)\n",
    "    threads = min(max_threads, n)\n",
    "    blocks = ceil(Int, n/threads)\n",
    "    \n",
    "    @cuda (blocks, threads) kernel_dist(a_cu, b_cu, c_cu)\n",
    "    c = Array(c_cu)\n",
    "    destroy!(ctx)\n",
    "    return c\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = Int64(5e8)\n",
    "n1 = @spawn distmontegpu(samples);\n",
    "n2 = @spawn distmontegpu(samples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_double = 4*(count(x->x<0.25,fetch(n1))+count(x->x<0.25,fetch(n2)))/(length(workers())*samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_double"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = Int64(1e8)\n",
    "r3 = remotecall(distmontegpu, 1, samples)\n",
    "r1 = remotecall(distmontegpu, 2, samples)\n",
    "r2 = remotecall(distmontegpu, 3, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_double = 4*(count(x->x<0.25,remotecall_fetch(getindex, 2, r1))+\n",
    "    count(x->x<0.25,remotecall_fetch(getindex, 3, r2))+\n",
    "    count(x->x<0.25,remotecall_fetch(getindex, 1, r3)))/(3*samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* r1,r2,r3 continues to reside on each worker even after fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = Int64(1e8)\n",
    "pi_double = 4*(count(x->x<0.25,remotecall_fetch(distmontegpu, 2, samples))+\n",
    "    count(x->x<0.25,remotecall_fetch(distmontegpu, 3, samples)))/(2*samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(gpu1[1])\n",
    "println(length(gpu1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(gpu2[1])\n",
    "println(length(gpu2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@printf \"%.15f\" abs(π - pi_single) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@printf \"%.15f\" abs(π - pi_double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### @parallel - The go-to tool for handling small tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addprocs([(\"root@10.4.1.4:6666\", 1)], tunnel=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0\n",
    "tic()\n",
    "for i in 1:200000000\n",
    "    sum += i\n",
    "end\n",
    "toc()\n",
    "println(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic()\n",
    "sum = @parallel (+) for i = 1:200000000\n",
    "    Int(i)\n",
    "end\n",
    "toc()\n",
    "println(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (daaaaaaaaaaamn!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
